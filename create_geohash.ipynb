{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "from glob import glob\n",
    "from unidecode import unidecode\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from shapely.geometry import Polygon, MultiPolygon, shape, Point, box\n",
    "import geohash\n",
    "from tqdm import tqdm\n",
    "from multiprocessing import Pool\n",
    "import rasterio as rio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def area_cat(area):\n",
    "    if area < 0.001:\n",
    "        return '< 0.001'\n",
    "    elif area >= 0.001 and area < 0.5:\n",
    "        return '0.001 - 0.5'\n",
    "    elif area >= 0.5 and area < 1:\n",
    "        return '0.5 - 1'\n",
    "    elif area >= 1 and area < 2:\n",
    "        return '1 - 2'\n",
    "    elif area >= 2 and area < 4:\n",
    "        return '2 - 4'\n",
    "    elif area >= 4 and area < 8:\n",
    "        return '4 - 8'\n",
    "    elif area >= 8 and area < 10:\n",
    "        return '8 - 10'\n",
    "    elif area >= 10 and area < 20:\n",
    "        return '10 - 20'\n",
    "    elif area >= 20 and area < 30:\n",
    "        return '20 - 30'\n",
    "    elif area >= 30 and area < 40:\n",
    "        return '30 - 40'\n",
    "    elif area >= 40 and area < 50:\n",
    "        return '40 - 50'\n",
    "    elif area >= 50 and area < 100:\n",
    "        return '50 - 100'\n",
    "    elif area >= 100 and area < 150:\n",
    "        return '100 - 150'\n",
    "    elif area >= 150 and area < 300:\n",
    "        return '150 - 300'\n",
    "    elif area >= 300 and area < 450:\n",
    "        return '300 - 450'\n",
    "    elif area >= 450 and area < 600:\n",
    "        return '450 - 600'\n",
    "    elif area >= 600 and area < 750:\n",
    "        return '600 - 750'\n",
    "    elif area >= 750 and area < 900:\n",
    "        return '750 - 900'\n",
    "    elif area >= 900 and area < 1000:\n",
    "        return '900 - 1000'\n",
    "    elif area >= 1000 and area < 2000:\n",
    "        return '1000 - 2000'\n",
    "    elif area > 2000:\n",
    "        return '> 2000'\n",
    "\n",
    "def geohash_grid7(geometry):\n",
    "    geohashes = set()\n",
    "    precision = 7\n",
    "    if geometry.geom_type == 'Polygon':\n",
    "        min_lon, min_lat, max_lon, max_lat = geometry.bounds\n",
    "        # Calcula os geohashes para cada ponto da grade\n",
    "        for lat in np.arange(min_lat, max_lat, 0.0005):\n",
    "            for lon in np.arange(min_lon, max_lon , 0.0005):\n",
    "                geohash_ = geohash.encode(lat, lon, precision=precision)\n",
    "                geohashes.add(geohash_)\n",
    "    elif geometry.geom_type == 'MultiPolygon':\n",
    "        for ap in geometry.geoms:\n",
    "            min_lon, min_lat, max_lon, max_lat = ap.bounds\n",
    "            for lat in np.arange(min_lat, max_lat, 0.0005):\n",
    "                for lon in np.arange(min_lon, max_lon , 0.0005):\n",
    "                    geohash_ = geohash.encode(lat, lon, precision=precision)\n",
    "                    geohashes.add(geohash_)\n",
    "    return list(geohashes) \n",
    "\n",
    "def geohash_grid5(geometry):\n",
    "    geohashes = set()\n",
    "    precision = 5\n",
    "    if geometry.geom_type == 'Polygon':\n",
    "        min_lon, min_lat, max_lon, max_lat = geometry.bounds\n",
    "        # Calcula os geohashes para cada ponto da grade\n",
    "        for lat in np.arange(min_lat, max_lat, 0.0005):\n",
    "            for lon in np.arange(min_lon, max_lon , 0.0005):\n",
    "                geohash_ = geohash.encode(lat, lon, precision=precision)\n",
    "                geohashes.add(geohash_)\n",
    "    elif geometry.geom_type == 'MultiPolygon':\n",
    "        for ap in geometry.geoms:\n",
    "            min_lon, min_lat, max_lon, max_lat = ap.bounds\n",
    "            for lat in np.arange(min_lat, max_lat, 0.0005):\n",
    "                for lon in np.arange(min_lon, max_lon , 0.0005):\n",
    "                    geohash_ = geohash.encode(lat, lon, precision=precision)\n",
    "                    geohashes.add(geohash_)\n",
    "    return list(geohashes) \n",
    "\n",
    "def geohash_grid4(geometry):\n",
    "    geohashes = set()\n",
    "    precision = 4\n",
    "    if geometry.geom_type == 'Polygon':\n",
    "        min_lon, min_lat, max_lon, max_lat = geometry.bounds\n",
    "        # Calcula os geohashes para cada ponto da grade\n",
    "        for lat in np.arange(min_lat, max_lat, 0.0005):\n",
    "            for lon in np.arange(min_lon, max_lon , 0.0005):\n",
    "                geohash_ = geohash.encode(lat, lon, precision=precision)\n",
    "                geohashes.add(geohash_)\n",
    "    elif geometry.geom_type == 'MultiPolygon':\n",
    "        for ap in geometry.geoms:\n",
    "            min_lon, min_lat, max_lon, max_lat = ap.bounds\n",
    "            for lat in np.arange(min_lat, max_lat, 0.0005):\n",
    "                for lon in np.arange(min_lon, max_lon , 0.0005):\n",
    "                    geohash_ = geohash.encode(lat, lon, precision=precision)\n",
    "                    geohashes.add(geohash_)\n",
    "    return list(geohashes) \n",
    "\n",
    "def geohash_grid3(geometry):\n",
    "    geohashes = set()\n",
    "    precision = 3\n",
    "    if geometry.geom_type == 'Polygon':\n",
    "        min_lon, min_lat, max_lon, max_lat = geometry.bounds\n",
    "        # Calcula os geohashes para cada ponto da grade\n",
    "        for lat in np.arange(min_lat, max_lat, 0.0005):\n",
    "            for lon in np.arange(min_lon, max_lon , 0.0005):\n",
    "                geohash_ = geohash.encode(lat, lon, precision=precision)\n",
    "                geohashes.add(geohash_)\n",
    "    elif geometry.geom_type == 'MultiPolygon':\n",
    "        for ap in geometry.geoms:\n",
    "            min_lon, min_lat, max_lon, max_lat = ap.bounds\n",
    "            for lat in np.arange(min_lat, max_lat, 0.0005):\n",
    "                for lon in np.arange(min_lon, max_lon , 0.0005):\n",
    "                    geohash_ = geohash.encode(lat, lon, precision=precision)\n",
    "                    geohashes.add(geohash_)\n",
    "    return list(geohashes) \n",
    "\n",
    "\n",
    "def geohash_grid6(geometry):\n",
    "    geohashes = set()\n",
    "    precision = 6\n",
    "    if geometry.geom_type == 'Polygon':\n",
    "        min_lon, min_lat, max_lon, max_lat = geometry.bounds\n",
    "        # Calcula os geohashes para cada ponto da grade\n",
    "        for lat in np.arange(min_lat, max_lat, 0.0005):\n",
    "            for lon in np.arange(min_lon, max_lon , 0.0005):\n",
    "                geohash_ = geohash.encode(lat, lon, precision=precision)\n",
    "                geohashes.add(geohash_)\n",
    "    elif geometry.geom_type == 'MultiPolygon':\n",
    "        for ap in geometry.geoms:\n",
    "            min_lon, min_lat, max_lon, max_lat = ap.bounds\n",
    "            for lat in np.arange(min_lat, max_lat, 0.0005):\n",
    "                for lon in np.arange(min_lon, max_lon , 0.0005):\n",
    "                    geohash_ = geohash.encode(lat, lon, precision=precision)\n",
    "                    geohashes.add(geohash_)\n",
    "    return list(geohashes) \n",
    "\n",
    "def get_geohash(geom):\n",
    "    centroid = geom.centroid\n",
    "    return geohash.encode(centroid.y, centroid.x, precision=14)\n",
    "\n",
    "def hash_box(stext):\n",
    "    hash_codenadas=geohash.bbox(stext)\n",
    "    return hash_codenadas['w'], hash_codenadas['n'], hash_codenadas['e'], hash_codenadas['s']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Os dados foram obtido com Observatorio da Restauracao no dia 26-04-2024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files=glob('../orr26042024/output/*.gpkg')\n",
    "files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agregar os dados e remover duplicados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coll = set()\n",
    "data = []\n",
    "for file in files:\n",
    "    try:\n",
    "        gdf = gpd.read_file(file)\n",
    "        gdf = gdf.rename(columns={'metprinci':'met_princ'})\n",
    "        gdf['area_ha'] = gdf.to_crs(5880).area / 10_000 \n",
    "        gdf['area_cat'] = gdf['area_ha'].apply(area_cat)\n",
    "        gdf['file'] = file\n",
    "        gdf = gdf[['met_princ', 'met_comb','area_ha','area_cat','file','geometry']]\n",
    "        data.append(gdf)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(file,gdf.columns, e)\n",
    "\n",
    "all_df = gpd.GeoDataFrame(pd.concat(data)).to_crs(4326)\n",
    "all_df['hash'] = all_df['geometry'].apply(get_geohash)\n",
    "clear = all_df.drop_duplicates(subset=['hash']).copy()\n",
    "\n",
    "clear[['met_princ', 'met_comb', 'area_ha', 'area_cat', 'file', 'geometry']].to_file('all_data.gpkg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clear['hash7'] = clear.geometry.apply(geohash_grid7)\n",
    "clear['hash5'] = clear.geometry.apply(geohash_grid5)\n",
    "clear['hash3'] = clear.geometry.apply(geohash_grid3)\n",
    "clear['hash4'] = clear.geometry.apply(geohash_grid4)\n",
    "clear['hash6'] = clear.geometry.apply(geohash_grid6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col_hash in ['hash7']:\n",
    "    set_hash = set()\n",
    "    for i in clear[col_hash]:\n",
    "        set_hash.update(i)\n",
    "\n",
    "\n",
    "    tmp = gpd.GeoDataFrame([{\n",
    "        'hash':hash_,\n",
    "        'geometry':box(*hash_box(hash_))} for hash_ in set_hash],crs=4326).to_crs(3857)\n",
    "    \n",
    "    tmp.to_file(f'amostra_{col_hash}.gpkg')\n",
    "    tmp.to_file(f'amostra_{col_hash}.shp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allhash = []\n",
    "\n",
    "for a in tqdm(clear['hash6'].unique()):\n",
    "\n",
    "    for i in '0123456789bcdefghjkmnpqrstuvwxyz':\n",
    "        allhash.append({\n",
    "            'hash': f'{a}{i}',\n",
    "            'geometry': box(*hash_box(f'{a}{i}'))})\n",
    "\n",
    "gdf_d = gpd.GeoDataFrame(allhash,geometry='geometry', crs=4326)\n",
    "gdf_d.to_file('amostra7_fulldata.gpkg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
