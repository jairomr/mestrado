{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "<p align=\"center\">\n",
    "  <img src=\"../assets/imgs/creat_area_amostras.svg\" alt=\"drawing\" style=\"width:600px;\"/>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "from glob import glob\n",
    "import pandas as pd\n",
    "from shapely.geometry import box\n",
    "import geohash\n",
    "import numpy as np\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def area_cat(area):\n",
    "    if area < 0.001:\n",
    "        return '< 0.001'\n",
    "    elif area < 0.5:\n",
    "        return '0.001 - 0.5'\n",
    "    elif area < 1:\n",
    "        return '0.5 - 1'\n",
    "    elif area < 2:\n",
    "        return '1 - 2'\n",
    "    elif area < 4:\n",
    "        return '2 - 4'\n",
    "    elif area < 8:\n",
    "        return '4 - 8'\n",
    "    elif area < 10:\n",
    "        return '8 - 10'\n",
    "    elif area < 20:\n",
    "        return '10 - 20'\n",
    "    elif area < 30:\n",
    "        return '20 - 30'\n",
    "    elif area < 40:\n",
    "        return '30 - 40'\n",
    "    elif area < 50:\n",
    "        return '40 - 50'\n",
    "    elif area < 100:\n",
    "        return '50 - 100'\n",
    "    elif area < 150:\n",
    "        return '100 - 150'\n",
    "    elif area < 300:\n",
    "        return '150 - 300'\n",
    "    elif area < 450:\n",
    "        return '300 - 450'\n",
    "    elif area < 600:\n",
    "        return '450 - 600'\n",
    "    elif area < 750:\n",
    "        return '600 - 750'\n",
    "    elif area < 900:\n",
    "        return '750 - 900'\n",
    "    elif area < 1000:\n",
    "        return '900 - 1000'\n",
    "    elif area < 2000:\n",
    "        return '1000 - 2000'\n",
    "    else:\n",
    "        return '> 2000'\n",
    "\n",
    "def geohash_grid(geometry, precision):\n",
    "    geohashes = set()\n",
    "    min_lon, min_lat, max_lon, max_lat = geometry.bounds\n",
    "    \n",
    "    for lat in np.arange(min_lat, max_lat, 0.0005):\n",
    "        for lon in np.arange(min_lon, max_lon, 0.0005):\n",
    "            geohashes.add(geohash.encode(lat, lon, precision=precision))\n",
    "    return list(geohashes)\n",
    "\n",
    "def get_geohash(geom, precision=14):\n",
    "    centroid = geom.centroid\n",
    "    return geohash.encode(centroid.y, centroid.x, precision=precision)\n",
    "\n",
    "def hash_box(geohash_code):\n",
    "    bbox = geohash.bbox(geohash_code)\n",
    "    return bbox['w'], bbox['n'], bbox['e'], bbox['s']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Os dados foram obtido com Observatorio da Restauracao no dia 26-04-2024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files=glob('../orr26042024/output/*.gpkg')\n",
    "files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agregar os dados e remover duplicados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "\n",
    "for file in files:\n",
    "    try:\n",
    "        gdf = gpd.read_file(file)\n",
    "        gdf = gdf.rename(columns={'metprinci': 'met_princ'})\n",
    "        gdf['area_ha'] = gdf.to_crs(5880).area / 10_000\n",
    "        gdf['area_cat'] = gdf['area_ha'].apply(area_cat)\n",
    "        gdf['file'] = file\n",
    "        gdf = gdf[['met_princ', 'met_comb', 'area_ha', 'area_cat', 'file', 'geometry']]\n",
    "        data.append(gdf)\n",
    "    except Exception as e:\n",
    "        print(f\"Erro no arquivo {file}: {e}\")\n",
    "\n",
    "# Concatena todos os dados em um Ãºnico GeoDataFrame\n",
    "all_df = gpd.GeoDataFrame(pd.concat(data)).to_crs(4326)\n",
    "all_df['hash'] = all_df['geometry'].apply(get_geohash)\n",
    "clear = all_df.drop_duplicates(subset=['hash']).copy()\n",
    "\n",
    "# Salva dados limpos em um arquivo\n",
    "clear[['met_princ', 'met_comb', 'area_ha', 'area_cat', 'file', 'geometry']].to_file('all_data.gpkg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precisions = [3,6]\n",
    "for precision in precisions:\n",
    "    col_hash = f'hash{precision}'\n",
    "    clear[col_hash] = clear.geometry.apply(lambda geom: geohash_grid(geom, precision=precision))\n",
    "\n",
    "    set_hash = set()\n",
    "    for hashes in clear[col_hash]:\n",
    "        set_hash.update(hashes)\n",
    "\n",
    "    tmp = gpd.GeoDataFrame(\n",
    "        [{'hash': h, 'geometry': box(*hash_box(h))} for h in set_hash], crs=4326).to_crs(3857)\n",
    "    tmp.to_file(f'amostra_hash{precision}.gpkg')\n",
    "    tmp.to_file(f'amostra_hash{precision}.shp')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allhash = []\n",
    "for base_hash in tqdm(clear['hash6'].unique()):\n",
    "    for suffix in '0123456789bcdefghjkmnpqrstuvwxyz':\n",
    "        allhash.append({\n",
    "            'hash': f'{base_hash}{suffix}',\n",
    "            'geometry': box(*hash_box(f'{base_hash}{suffix}'))\n",
    "        })\n",
    "\n",
    "gdf_d = gpd.GeoDataFrame(allhash, geometry='geometry', crs=4326)\n",
    "gdf_d.to_file('amostra7_fulldata.gpkg')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
