{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "from glob import glob\n",
    "from shapely.geometry import Polygon, MultiPolygon, shape, Point, box\n",
    "from tqdm import tqdm\n",
    "import geohash\n",
    "data = []\n",
    "\n",
    "from colormap import rgb2hex\n",
    "\n",
    "\n",
    "_class = [\n",
    "    {'class': 'PASTURE', 'selected': False, 'rgba': '237, 222, 142, 77'},\n",
    "    {'class': 'FOREST FORMATION', 'selected': False, 'rgba': '50, 166, 94, 77'},\n",
    "    {'class': 'AGRICULTURE', 'selected': False, 'rgba': '233, 116, 237, 77'},\n",
    "    {'class': 'AGROPEC', 'selected': False, 'rgba': '255, 255, 178, 77'},\n",
    "    {'class': 'FOREST PLANT', 'selected': False, 'rgba': '122, 89, 0, 77'},\n",
    "    {'class': 'URBAN', 'selected': False, 'rgba': '212, 39, 30, 77'},\n",
    "    {'class': 'SAVANNA', 'selected': False, 'rgba': '125, 201, 117, 77'},\n",
    "    {'class': 'WATER', 'selected': False, 'rgba': '0, 0, 255, 77'},\n",
    "    {'class': 'FLOODED AREA', 'selected': False, 'rgba': '2, 105, 117, 77'},\n",
    "    {'class': 'WOODED SANDBANK', 'selected': False, 'rgba': '2, 214, 89, 77'},\n",
    "    {'class': 'GRASSLAND', 'selected': False, 'rgba': '214, 188, 116, 77'},\n",
    "    {'class': 'COFF', 'selected': False, 'rgba': '214, 143, 226, 77'},\n",
    "    {'class': 'MANGROVE', 'selected': False, 'rgba': '4, 56, 29, 77'},\n",
    "    {'class': 'MINING', 'selected': False, 'rgba': '156, 0, 39, 77'},\n",
    "    {'class': 'ROCKY', 'selected': False, 'rgba': '255, 170, 95, 77'},\n",
    "    {'class': 'NON FOREST', 'selected': False, 'rgba': '173, 151, 90, 77'},\n",
    "    {'class': 'APICUM', 'selected': False, 'rgba': '252, 129, 20, 77'},\n",
    "    {'class': 'HERBACEOUS SANDBANK', 'selected': False, 'rgba': '173, 81, 0, 77'},\n",
    "    {'class': 'ASPHALT', 'selected': False, 'rgba': '206, 206, 206, 77'}\n",
    " ]\n",
    "\n",
    "#for i, c in enumerate(_class,1):\n",
    "#    print(f\"'{rgb2hex(*[int(n) for n in c['rgba'].split(', ')[0:3]])}', // {i} {c['class']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "replace = {}\n",
    "\n",
    "old = gpd.read_file('data/amostra_rois_v5_3857.gpkg')\n",
    "\n",
    "def getbox(row):\n",
    "    return box(row['left'], row['top'], row['right'], row['bottom']).centroid\n",
    "\n",
    "for i, c in enumerate(_class,1):\n",
    "    replace[c['class']] = str(i)\n",
    "     \n",
    "\n",
    "def asint(x):\n",
    "    if x is None:\n",
    "        return 0\n",
    "    return int(x)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_geohash(c):\n",
    "    return geohash.encode(c.y, c.x, precision=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf = gpd.read_file(glob('../*/*.gpkg')[0])\n",
    "_hash = get_geohash(gdf.to_crs(4326).geometry.unary_union.centroid)\n",
    "old[old['hash'] == _hash].empty\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in tqdm(glob('../*/*.gpkg')):\n",
    "    \n",
    "    tmp = gpd.read_file(file)\n",
    "    _hash = get_geohash(tmp.to_crs(4326).geometry.unary_union.centroid)\n",
    "    if not old[old['hash'] == _hash].empty:\n",
    "        tmp['class_id'] = tmp['bing_class'].replace(replace).apply(asint)\n",
    "        tmp['hash_macro'] = _hash[:6]\n",
    "        tmp['hash_micro'] = _hash\n",
    "        tmp['class_name'] = tmp['bing_class']\n",
    "        tmp['geometry'] = tmp.apply(getbox, axis=1)\n",
    "        tmp = tmp[['hash_macro', 'hash_micro', 'class_id', 'class_name', 'geometry']]\n",
    "        data.append(tmp.set_crs(3857))\n",
    "    \n",
    "gdf = pd.concat(data)\n",
    "\n",
    "gdf = gdf[gdf['class_id'] > 0]\n",
    "\n",
    "gdf['id'] = gdf.reset_index().index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf['hash1'] = gdf['hash_macro'].apply(lambda x:x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_amostra = 35_000\n",
    "\n",
    "\n",
    "\n",
    "dataf = []\n",
    "for macro in gdf['hash1'].unique():\n",
    "    gdf_macro = gdf[gdf['hash1'] == macro].copy()\n",
    "    micros = gdf_macro['hash_micro'].unique()\n",
    "    total_micros = len(micros)\n",
    "    total_group = total_amostra // total_micros\n",
    "    print(total_amostra , total_group, total_micros)\n",
    "    print(len(gdf_macro))\n",
    "    rows = []\n",
    "    if len(gdf_macro) < total_amostra:\n",
    "        \n",
    "        dataf.append(gdf_macro)\n",
    "    else:\n",
    "        for micro in gdf_macro['hash_micro'].unique():\n",
    "            gdf_micro = gdf_macro[gdf_macro['hash_micro'] == micro]\n",
    "            \n",
    "            class_id = gdf_micro['class_id'].unique()\n",
    "            total_class = len(class_id)\n",
    "            \n",
    "            for c in class_id:\n",
    "                gdf_class = gdf_micro[gdf_micro['class_id'] == c]\n",
    "                if len(gdf_class) < total_group//total_class:\n",
    "                    rows.append(gdf_class)\n",
    "                    #print(f'get total micro {micro} class {c}')\n",
    "                else:\n",
    "                    #print(f'Processando micro {micro} class {c} {total_group//total_class}')\n",
    "                    gdf_class = gdf_class.sample(n=total_group//total_class, replace=False, random_state=42)\n",
    "                    \n",
    "                    rows.append(gdf_class)\n",
    "        \n",
    "        tmp = pd.concat(rows)\n",
    "        \n",
    "        clear = gdf_macro[~gdf_macro['id'].isin(tmp['id'])]\n",
    "        print(len(tmp))\n",
    "        print(total_amostra - len(tmp), len(clear))\n",
    "    \n",
    "        dataf.append( tmp)#, clear.sample(n=total_amostra-len(tmp), replace=False) ])\n",
    "\n",
    "amostras_okey = pd.concat(dataf)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "amostras_okey.to_file('data/amostras_cerrado5_clearv3.shp')"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
